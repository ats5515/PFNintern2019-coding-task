# PFNintern2019-coding-task
PFN2019年夏季インターンコーディング課題からmachine learningを選択して解きました。使用言語はc++です。

[2019年 PFN夏季インターンシップのコーディング課題公開](https://research.preferred.jp/2019/06/internship-coding-task-2019/)

## 課題概要
課題はGNNのスクラッチ実装でした。全部で4問あり、課題１はGNNの実装とテスト、課題２は数値微分による学習、課題３は学習方法としてSGDとMomentumSGDの実装と比較、課題4はモデルに自由に変化を加える、というものでした。また、課題3と4では実データに対して適用およびテストデータに対する予測ラベルの提出と、取り組みを纏めたレポートを提出の指示があります。

スクラッチ実装というと難しそうですが、課題pdfに親切に実装すべきことが書かれているので機械学習に関する事前知識はほぼ必要なく、コーディングとしても難しくはないです。自分の頭で理解、発想した上で実装したりレポートにしたりする能力が問われているのだと思いました。

## やったこと
report.pdfを参照して下さい。

重要だと思ったのは、配布された問題pdfそのままの実装だと、各頂点に割り当てるベクトルの次元（問題文中の$D$）をいくら大きくしてもモデルとしての表現力が変わらないという問題が発生するという点です。課題4は自由にモデルに変更を加えて実装せよというものだったので、この問題を解決することレポートの目的としました。

提出レポートは2ページまでの制約があり、上手く説明できなかったので補足します。

問題は、グラフの頂点の表現ベクトルの比率がどんなグラフを入力にしても一定となってしまい、次元をいくら増やしても実質的に１次元分の表現力しか持たないという点にあります。

なお、report.pdfではこの原因を活性化関数ReLUが「乗法的関数」だからと述べていますが、これは間違いで正しくは「1時の斉次函数」というべきもので、任意の$a,x$に対し$f(ax)=af(x)$が成り立つというものです。

解決方法としては、活性化関数を変えるか、定数項を追加するかして、特徴ベクトルの比が一定になってしまうのを阻止すればよいです。定数項を追加するだけで配布されたデータに対する正解率は65％から85％まで上がります。

レポートでは、さらに活性化関数を変えて性能の変化を見ました。このテストデータに対しては活性化関数にコサイン関数を使っても性能が落ちない（画像処理タスク（CNN）で使うと性能が下がるといわれている気がする）ということが分かったので、遊び心からもコサイン関数を使ったモデルを最終的に採用しました。

## 実行方法
git clone後、配布されているデータセット（datasetsディレクトリ）を置く

コンパイル
```bash
./compile.sh
```
生成される実行ファイル
- task1:	課題1の内容に対応。GNNの出力が期待されるものと一致しているかをチェックする。 
- task2:	課題2の内容に対応。勾配降下法によって1データに対して学習し、損失関数が十分小さくなることを確認。
- task3:	課題3の内容に対応。与えられたデータに対し、SGDとMomdentumSGDで学習し、損失と精度の変化をファイル出力する
- task4:	課題4の内容に対応。レポートに示したいくつかの実験を行う。
- predict:	課題4の内容に対応。与えられたテストデータに対し予測を行い、prediction.txtを生成する。

引数などの指定はない。"./task1"などとコマンドを叩いて実行


## 各ソースファイルの概要
- Graph.hpp:	グラフクラスの実装。グラフは隣接リストによって保持する。
- Matrix.hpp:	行列・ベクトルを定義。行列・ベクトル上の演算や入出力を実装。
- Functions.hpp:	関数群（特に、活性化関数）を実装。
- Loss.hpp:	損失関数を実装
- DataSet.hpp:	データセットの読み込み、分割などを実装。
- Model.hpp:	機械学習モデルの抽象クラス。
- Optimizer.hpp:	最適化器の抽象クラス。
- Util.hpp:	便利関数の実装

- Modelクラスのサブクラス
  - GNN.hpp:	グラフを入力して特徴量ベクトルを得るまでを担当
  - GNN2.hpp:	定数項ありのGNN(レポート参照)を実装
  - LinearClassifier.hpp:
		二値線形分類器の実装。実行時速度を考え、出力はシグモイド関数にかける前の値とした。
  - GNN_Classifier.hpp:
		GNNと線形分類器をつなげたもの。今回学習や予測に使うモデル。

- Optimizerクラスのサブクラス
  - GradientDescent.hpp:
		勾配降下法の実装
  - SGD.hpp:	SGDの実装
  - MomentumSGD.hpp:MomentumSGDの実装
  - Adam.hpp:	Adamの実装	